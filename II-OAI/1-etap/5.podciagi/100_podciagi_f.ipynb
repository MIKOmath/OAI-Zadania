{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7F3RXedd92V"
      },
      "source": [
        "# Ukryte Podciągi\n",
        "![](https://live.staticflickr.com/65535/54327633282_6bc45ba42a_o.png)\n",
        "\n",
        "*Obraz wygenerowany przy użyciu modelu DALL-E.*\n",
        "\n",
        "## Wstęp\n",
        "Od starożytnych wróżbitów interpretujących układ gwiazd po współczesnych kryptografów tropiących ślady ukrytych wiadomości, ludzkość od zawsze poszukiwała sensu w pozornie chaotycznych danych. Czasem kluczowe informacje ukrywają się w drobnych sekwencjach symboli, a ich wartość ujawnia się dopiero po precyzyjnej analizie.\n",
        "\n",
        "W tym zadaniu wcielisz się w rolę detektywa, poszukującego strukturalnych zależności w zbiorze binarnych ciągów. Będziesz dysponował zbiorem danych zawierającym przykładowe ciągi oraz ich poprawnie obliczone wartości. Twoim celem będzie opracowanie metody analizy ukrytych wzorców pozwalającej na możliwie najprecyzyjniejsze wyznaczanie wartości ciągów niewystępujących w zbiorze.\n",
        "\n",
        "Mówimy, że ciąg $T$ jest podciągiem $S$ i oznaczamy $T \\subseteq S$ jeżeli\n",
        "$$\n",
        "T = S_{i_1}S_{i_2} \\dots S_{i_k}\n",
        "$$\n",
        "Gdzie\n",
        "$$\n",
        "1 \\leq i_1 < i_2 < \\dots < i_k \\leq n\n",
        "$$\n",
        "Dla $k$ i $n$ będących długościami ciągów $T$ i $S$ odpowiednio, oraz indeksów ($i_1 < i_2 < \\dots < i_k$) będących ściśle rosnącym ciągiem liczb naturalnych (niekoniecznie kolejnych).\n",
        "\n",
        "Rozwiązaniem dla danego ciągu binarnego $S \\in \\{0,1\\}^{n}$ oraz zdefiniowanego zbioru zawierającego kolejno wzorzec i jego wagę $W = \\{(T, v):T \\in \\{0,1\\}^{k}, k \\le n, v \\in Z\\}$ jest liczba\n",
        "$$\n",
        "\\phi(S) = \\sum_{(T_{i}, v_{i}) \\in W} v_{i} \\cdot \\text{I} (T_{i})\n",
        "$$\n",
        "gdzie $\\text{I}(T_{i}) = \\begin{cases}\n",
        "1, & T_{i} \\subseteq S \\\\\n",
        "0, & T_{i} \\subsetneq S\n",
        "\\end{cases}$\n",
        "\n",
        "Innymi słowy, $\\phi(S)$ jest sumą wartości wszystkich ciągów ze zbioru $W$, które są podciągami $S$.\n",
        "\n",
        "**Przykład:**\n",
        "Dla zbioru $W = \\{(1111, 1), (1010, 2)\\}$, mamy:\n",
        "- $\\phi$(0**1111**000) = 1\n",
        "- $\\phi$(1**10**00**1**0**0**) = 2\n",
        "- $\\phi$(0**110110**0) = 3,  ponieważ\n",
        "\n",
        "  - 1111 $\\subseteq$ 0**11**0**11**00\n",
        "\n",
        "  - 1010 $\\subseteq$ 01**101**1**0**0\n",
        "- $\\phi$(01100000) = 0, ponieważ 1111, 1010 $\\subsetneq$ 01100000.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV6IfA7id92W"
      },
      "source": [
        "## Zadanie\n",
        "Stwórz model (obiekt typu `nn.Module`) który będzie znajdował wartość $\\phi$ dla ciągów ze zbioru danych. Dane treningowe składają się z ciągów $S$ oraz odpowiadających im wartości $\\phi(S)$. Zauważ więc, że wzorzec $W$ jest ukryty, a Twoim zadaniem jest przybliżyć $\\phi$ bez wiedzy o nim.\n",
        "\n",
        "Twój model musi przyjmować na wejściu dane w postaci $(\\text{batch}, n)$. Natomiast na wyjściu musi zwracać wartości w postaci $(\\text{batch}, 1)$ lub $(\\text{batch},)$, gdzie $\\text{batch}$ to liczba próbek.\n",
        "\n",
        "### Dane\n",
        "Dane dostępne dla Ciebie w tym zadaniu to:\n",
        "* `train_dataset.csv`- plik z danymi na których będziesz trenować swój model\n",
        "* `val_dataset.csv`- plik z danymi na których przetestujesz swój model\n",
        "\n",
        "### Kryterium Oceny\n",
        "Zadanie zostanie ocenione na podstawie metryki [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (Mean Squared Error), która jest jedną z najczęściej stosowanych metryk do oceny jakości regresji.  \n",
        "\n",
        "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "Gdzie $y_i$ to wartość rzeczywista, a $\\hat{y}_i$ to wartość przewidziana przez model. Wartość $i$ to numer próbki, a $n$ to liczba wszystkich próbek.\n",
        "\n",
        "Ta metryka jest już przez nas zaimplementowana w tym notebooku.\n",
        "\n",
        "**Ostatecznie Twoje rozwiązanie oceniane będzie na tajnym zbiorze testowym na podstawie metryki MSE.** Zbiór testowy nie różni się znacząco od zbioru walidacyjnego.\n",
        "\n",
        "- Gdy wartość MSE dla Twojego modelu będzie wynosiła 64 (lub więcej), otrzymasz 0 punktów za zadanie\n",
        "- Gdy wartość MSE dla Twojego modelu będzie wynosiła 64 (lub mniej), otrzymasz X punktów za zadanie, gdzie X jest zdefiniowane w następujący sposób:\n",
        "$$\n",
        "\\text{X} = \\frac{64 - MSE}{64} \\times 100\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMFDG-od92X"
      },
      "source": [
        "## Ograniczenia\n",
        "- Twoje rozwiazanie będzie testowane na Platformie Konkursowej bez dostępu do internetu oraz w środowisku z GPU.\n",
        "- Ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie może trwać dłużej niż 4 minut z GPU.\n",
        "- Twój model może być trenowany maksymalnie przez 4000 iteracji, co odpowiada pojedynczemu przeiterowaniu przez zmienną ```dl``` (patrz na przykładowe rozwiązanie).\n",
        "- Twój model nie może mieć więcej niż 50000 parametrów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQjqemxd92Z"
      },
      "source": [
        "## Uwagi i Wskazówki\n",
        "- Każdy z ciągów ma taką samą, ustaloną długość.\n",
        "- Każdy z szukanych podciągów ma długość krótszą niż długość źródłowych ciągów.\n",
        "- Rozpatrujemy trzy podciągi. Każdy z nich ma przypisaną wartość, która jest liczbą całkowitą.\n",
        "- W każdym ciągu znajduje się dowolna liczba podciągów (w tym brak jakiegokolwiek z nich).\n",
        "- Ciągi i podciągi pochodzą z alfabetu binarnego oraz są reprezentowane w postaci list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzfkmFhid92Z"
      },
      "source": [
        "## Pliki Zgłoszeniowe\n",
        "Ten notebook uzupełniony o Twoje rozwiązanie (patrz klasa `YourModel` oraz trening modelu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz6YjcJgPYZA"
      },
      "source": [
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tc3PBZxd92a"
      },
      "source": [
        "# Kod Startowy\n",
        "\n",
        "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "uabMLs-Bd92b"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "FINAL_EVALUATION_MODE = False # Podczas sprawdzania ustawimy tą flagę na True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "bbbDUJFed92d"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import pandas\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "vxT9ittksAUM"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "def seed_everything(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Ustawia ziarno (seed) dla odtwarzalności wyników w Pythonie, NumPy oraz PyTorch.\n",
        "\n",
        "    Funkcja ustawia ziarno dla generatorów liczb losowych Pythonie, NumPy oraz PyTorch,\n",
        "    a także konfiguruje PyTorch do pracy w trybie deterministycznym.\n",
        "\n",
        "    Parametry:\n",
        "        seed (int): Wartość ziarna do ustawienia.\n",
        "    \"\"\"\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "BQ3OGpcKd92d"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "seed_everything(12345)\n",
        "\n",
        "device = 'cuda'\n",
        "assert torch.cuda.is_available(), \"CUDA niedostępna!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7XIsA3Fd92e"
      },
      "source": [
        "## Ładowanie Danych\n",
        "Za pomocą poniższego kodu wczytujemy dane zawierające ciągi wraz z ich wartościami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "mKFjUr8663z1"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "class CSVDataloader(torch.utils.data.DataLoader):\n",
        "    \"\"\"\n",
        "    Klasa CSVDataloader służy do ładowania danych z plików CSV i zwracania ich w batchach.\n",
        "\n",
        "    Przyjmuje:\n",
        "        csv_file (str): Ścieżka do pliku CSV.\n",
        "        batch_size (int): Rozmiar batcha.\n",
        "        shuffle (bool): Czy tasować dane.\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, batch_size=128, shuffle=True):\n",
        "\n",
        "        class CSVDataset(torch.utils.data.Dataset):\n",
        "            \"\"\"\n",
        "            Klasa CSVDataset służy do przechowywania danych z plików CSV jako pojedyncze próbki.\n",
        "            \"\"\"\n",
        "            def __init__(self, csv_file: str):\n",
        "                data = pandas.read_csv(csv_file).values\n",
        "                self.x = torch.tensor(data[:, :-1], dtype=torch.float32)  # Features\n",
        "                self.y = torch.tensor(data[:, -1], dtype=torch.float32)  # Labels\n",
        "\n",
        "            def __len__(self) -> int:\n",
        "                return len(self.x)\n",
        "\n",
        "            def __getitem__(self, idx: int) -> tuple:\n",
        "                return self.x[idx].long(), self.y[idx]\n",
        "\n",
        "        dataset = CSVDataset(csv_file)\n",
        "        self.seq_len = dataset.x.shape[1]\n",
        "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "arN5KYKe7Chf"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Inicjalizacja treningowego zbioru danych\n",
        "train_dataset_path = \"train_dataset.csv\"\n",
        "val_dataset_path = \"val_dataset.csv\"\n",
        "\n",
        "if not os.path.exists(train_dataset_path):\n",
        "    url = \"https://drive.google.com/uc?id=1INeYNpPA_YwojuQbMizlsFsERJ-PJX-E\"\n",
        "    gdown.download(url, train_dataset_path, quiet=True)\n",
        "\n",
        "if not os.path.exists(val_dataset_path):\n",
        "    url = \"https://drive.google.com/uc?id=1oQcOMyDWVX0x76LOyp4TcFip1koRuodN\"\n",
        "    gdown.download(url, val_dataset_path, quiet=True)\n",
        "\n",
        "dl = CSVDataloader(\"train_dataset.csv\")\n",
        "val_dl = CSVDataloader(\"val_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA-aEkMpd92i"
      },
      "source": [
        "## Kod z Kryterium Oceniającym\n",
        "\n",
        "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "h8EmbPHKd92i"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "def mse_criterium(\n",
        "        estimations: torch.Tensor,\n",
        "        answers: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Oblicza wartość funkcji błędu średniokwadratowego (MSE) pomiędzy predykcjami a prawdziwymi wartościami.\n",
        "\n",
        "    Parametry:\n",
        "        estimations (torch.Tensor): Predykcje modelu.\n",
        "        answers (torch.Tensor): Prawdziwe wartości.\n",
        "\n",
        "    Zwraca:\n",
        "        torch.Tensor: Wartość funkcji błędu średniokwadratowego.\n",
        "    \"\"\"\n",
        "    return torch.mean((estimations.view(-1) - answers.view(-1)) ** 2)\n",
        "\n",
        "\n",
        "def validate_model(\n",
        "        model: torch.nn.Module,\n",
        "        val_dl: torch.utils.data.DataLoader,\n",
        "    ) -> float:\n",
        "    \"\"\"\n",
        "    Waliduje model na zbiorze walidacyjnym. Zwraca uśrednioną wartość\n",
        "    funkcji błędu średniokwadratowego dla wszystkich próbek.\n",
        "\n",
        "    Parametry:\n",
        "        model (torch.nn.Module): Model do oceny.\n",
        "        val_dl (torch.utils.data.DataLoader): DataLoader z danymi walidacyjnymi.\n",
        "\n",
        "    Zwraca:\n",
        "        float: Uśredniona wartość funkcji błędu średniokwadr\n",
        "    \"\"\"\n",
        "    model = model.eval().to(device)\n",
        "    values = []\n",
        "    for x, y in val_dl:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred = model(x)\n",
        "\n",
        "        mse = mse_criterium(y_pred, y).cpu().item()\n",
        "        values.append(mse)\n",
        "\n",
        "    final_value = torch.tensor(values).mean().item()\n",
        "\n",
        "    return final_value\n",
        "\n",
        "def estimate_points(mse: float) -> int:\n",
        "    \"\"\"\n",
        "    Funkcja wyznaczająca ilość punktów za zadanie na podstawie wartości funkcji błędu średniokwadratowego.\n",
        "\n",
        "    Parametry:\n",
        "        mse (float): Wartość funkcji błędu średniokwadratowego.\n",
        "\n",
        "    Zwraca:\n",
        "        int: Ilość punktów za zadanie (0 - 100).\n",
        "    \"\"\"\n",
        "    points = max((100 * (64 - mse)) / 64, 0)\n",
        "    return int(round(points))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVL00cmkd92j"
      },
      "source": [
        "## Przykładowe Rozwiązanie\n",
        "Poniżej przedstawiamy uproszczone rozwiązanie, które służy jako przykład demonstrujący podstawową funkcjonalność notatnika. Może ono posłużyć jako punkt wyjścia do opracowania Twojego rozwiązania.\n",
        "\n",
        "Jako prosty przykład może posłuży rozwiązanie bazujące na wielowarstwowej sieci neuronowej (ang. Multi-layered perceptron, MLP).\n",
        "W tym wypadku, ciągi zer i jedynek traktujemy jako wejście do naszej sieci, natomiast jej wyjściem modelujemy wartość danego ciągu. Minimalizując błąd średniokwadratowy (ang. mean squared error, MSE) uczymy sieć prawidłowo oszacowywać wartość podciągu na bazie jego elementów.\n",
        "\n",
        "Poniższa ilustracja ukazuje w jaki sposób uczymy nasz model prawidłowo oceniać wartości ciągów.\n",
        "\n",
        "![](https://live.staticflickr.com/65535/54328760659_2e9355bb07_c.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "DjJPyFPNfyxG"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Klasa reprezentująca model sieci MLP z czterema ukrytymi warstwami.\n",
        "\n",
        "    Parametry:\n",
        "        input_length (int): Długość wejścia sieci (długość sekwencji).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int):\n",
        "        super(MLP, self).__init__()\n",
        "        neurons_num = [256, 128, 64, 32]\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(input_length, neurons_num[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[0], neurons_num[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[1], neurons_num[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[2], neurons_num[3]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[3], 1),\n",
        "        )\n",
        "\n",
        "        print(\"Liczba parametrów:\", sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Funkcja przyjmująca sekwencje danych i zwracająca predykcje ich wartości za pomocą sieci MLP.\n",
        "\n",
        "        Parametry:\n",
        "            x (torch.Tensor): Sekwencja danych.\n",
        "\n",
        "        Zwraca:\n",
        "            torch.Tensor: Predykcje wartości sekwencji.\n",
        "        \"\"\"\n",
        "        x = x.float()\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJuCLkz8sAUQ"
      },
      "source": [
        "### Trening Przykładowego Modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "s_RzUTvRPYZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a74fbadd-6d54-4adb-acbd-cd70fc632471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba parametrów: 49665\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "\tmodel = MLP(dl.seq_len).to(device)\n",
        "\n",
        "\toptimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\tcriterion = nn.MSELoss()\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch in iter(dl): # pojedyncze przeiterowanie dl - 4000 batchy\n",
        "\t\tinputs, targets = batch\n",
        "\t\tinputs, targets = inputs.to(device).long(), targets.to(device).float().unsqueeze(1)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutputs = model(inputs)\n",
        "\n",
        "\t\tloss = criterion(outputs, targets)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzGX0P4isAUQ"
      },
      "source": [
        "### Ewaluacja Przykładowego Rozwiązania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqYyN9O9sAUQ",
        "outputId": "b0f72357-691f-4635-87a5-7e3234fd9a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Błąd średniokwadratowy: 109.82\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# walidacja przykładowego rozwiązania\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    score = validate_model(model, val_dl)\n",
        "    print(f\"Błąd średniokwadratowy: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lI1YSi3d92k"
      },
      "source": [
        "# Twoje Rozwiązanie\n",
        "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "c-e3OF2mPYZV"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "class GRUBasedModel(nn.Module):\n",
        "    def __init__(self, embedding_dim = 8, hidden_dim = 24, num_layers = 2):\n",
        "        super(GRUBasedModel, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.vals = nn.Parameter(torch.randn(3),requires_grad=True)\n",
        "\n",
        "        self.transformer_encoder = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim * 2, 4)\n",
        "        self.batch_norm = nn.BatchNorm1d(1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.transformer_encoder(x)\n",
        "\n",
        "        # Zdobywam wartości\n",
        "        out = self.fc_out(out)\n",
        "        actual_vals = torch.cat((self.vals,torch.tensor([0.0]).to(x.device))).unsqueeze(dim=0).unsqueeze(dim=0)\n",
        "        out = torch.softmax(out,dim=-1) # [batch_size,seq_len,4]\n",
        "        out = out * actual_vals # [batch_size,seq_len,4]\n",
        "\n",
        "        out = torch.sum(out,dim=-1).unsqueeze(dim=-1)\n",
        "\n",
        "        out = out.flatten(0,1)\n",
        "        out = self.batch_norm(out)\n",
        "        out = out.reshape(x.shape[0], x.shape[1])\n",
        "\n",
        "        return out # [batch_size,seq_len]\n",
        "\n",
        "\n",
        "class YourModel(nn.Module):\n",
        "    def __init__(self, sequence_len, num_experts = 2, embedding_dim = 8):\n",
        "        super(YourModel, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_experts = num_experts\n",
        "\n",
        "        self.embed = nn.Embedding(2, embedding_dim)\n",
        "\n",
        "        init.xavier_uniform_(self.embed.weight)\n",
        "\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, num_experts)\n",
        "        )\n",
        "\n",
        "        self.models = nn.ModuleList([GRUBasedModel() for i in range(num_experts)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Funkcja przyjmująca sekwencje danych i zwracająca predykcje ich wartości.\n",
        "\n",
        "        Parametry:\n",
        "            x (torch.Tensor): Sekwencja danych.\n",
        "\n",
        "        Zwraca:\n",
        "            torch.Tensor: Predykcje wartości sekwencji.\n",
        "        \"\"\"\n",
        "\n",
        "        inputs = self.embed(x)\n",
        "\n",
        "        decisions = torch.softmax(self.gate(inputs),dim=-1)\n",
        "\n",
        "        sum = torch.zeros(x.shape[0]).to(x.device)\n",
        "        for idx, model in enumerate(self.models):\n",
        "          out = model(inputs) * decisions[:, :, idx]\n",
        "          sum_out = torch.sum(out,dim=1)\n",
        "          sum += sum_out\n",
        "\n",
        "        return sum\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usg8rSA8PYZV"
      },
      "source": [
        "### Trening Twojego Modelu\n",
        "Tutaj zaimplementuj trening Twojego modelu."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5, last_epoch: int = -1\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "    initial lr set in the optimizer.\n",
        "\n",
        "    Args:\n",
        "        optimizer ([`~torch.optim.Optimizer`]):\n",
        "            The optimizer for which to schedule the learning rate.\n",
        "        num_warmup_steps (`int`):\n",
        "            The number of steps for the warmup phase.\n",
        "        num_training_steps (`int`):\n",
        "            The total number of training steps.\n",
        "        num_cycles (`float`, *optional*, defaults to 0.5):\n",
        "            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "            following a half-cosine).\n",
        "        last_epoch (`int`, *optional*, defaults to -1):\n",
        "            The index of the last epoch when resuming training.\n",
        "\n",
        "    Return:\n",
        "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "    \"\"\"\n",
        "\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
      ],
      "metadata": {
        "id": "VQ8x3IfBgt15"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iazcJG4OsAUR",
        "outputId": "6bfb8dea-c03c-468d-9648-aab1d3eda469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [00:00, 44.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1: 1389.45263671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "222it [00:02, 107.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 201: 860.7988330078125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "414it [00:04, 105.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 401: 302.55095962524416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "620it [00:06, 107.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 601: 87.0481481552124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "812it [00:07, 108.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 801: 32.37246605396271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1016it [00:09, 108.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1001: 12.710272462368012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1212it [00:11, 77.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1201: 7.238886932134628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1412it [00:14, 107.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1401: 4.547388184666634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1613it [00:16, 106.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1601: 3.1995392659306527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1812it [00:18, 106.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 1801: 3.2176432088017464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2013it [00:19, 105.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 2001: 2.670185893923044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2218it [00:21, 106.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 2201: 2.3316194009780884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2412it [00:23, 77.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 2401: 1.9167052651196719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2621it [00:26, 104.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 2601: 1.593154629394412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2814it [00:28, 105.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 2801: 1.9484231500327587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3017it [00:30, 103.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 3001: 1.771398904696107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3213it [00:31, 108.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 3201: 1.7390258871763944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3421it [00:33, 109.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 3401: 1.4086011434346437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3609it [00:35, 93.83it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 3601: 1.558974913842976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3815it [00:38, 100.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for batch 3801: 1.5558361519500614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4000it [00:40, 99.98it/s] \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_training_steps = 4000\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "seed_everything(12345)\n",
        "\n",
        "your_model = YourModel(dl.seq_len).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(your_model.parameters(), weight_decay=0.0, lr=3e-3)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "your_model.train()\n",
        "losses = []\n",
        "for idx, batch in tqdm(enumerate(iter(dl))):\n",
        "  inputs, targets = batch\n",
        "  inputs, targets = inputs.to(device).long(), targets.to(device).float().unsqueeze(1)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  outputs = your_model(inputs)\n",
        "\n",
        "  loss = criterion(outputs, targets.squeeze(dim=1))\n",
        "  loss.backward()\n",
        "\n",
        "  torch.nn.utils.clip_grad_norm_(your_model.parameters(), max_norm=1.0)\n",
        "\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "\n",
        "  if idx % 200 == 0:\n",
        "    print(f\"Loss for batch {idx + 1}: {np.mean(losses[-200:])}\")\n",
        "\n",
        "your_model = your_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8QbP1jZd92l"
      },
      "source": [
        "# Ewaluacja\n",
        "\n",
        "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "ez0ToRdbPYZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d22e832-102b-43fb-9d02-0931dccd0797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Błąd średniokwadratowy: 0.13\n",
            "Estymowane punkty za zadanie: 100\n"
          ]
        }
      ],
      "source": [
        "# ######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    assert sum(p.numel() for p in your_model.parameters()) < 50000, \"Model posiada za dużo parametrów\"\n",
        "\n",
        "    mse = validate_model(your_model, val_dl)\n",
        "    score = estimate_points(mse)\n",
        "\n",
        "    print(f\"Błąd średniokwadratowy: {mse:.2f}\")\n",
        "    print(f\"Estymowane punkty za zadanie: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nUDFqosAUS"
      },
      "source": [
        "Podczas sprawdzania model zostanie zapisany jako `your_model.pkl` i oceniony na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "OUgv10fNsAUS"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if FINAL_EVALUATION_MODE:\n",
        "    import cloudpickle\n",
        "\n",
        "    OUTPUT_PATH = \"file_output\"\n",
        "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
        "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    your_model = your_model.eval()\n",
        "\n",
        "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
        "        cloudpickle.dump(your_model, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}