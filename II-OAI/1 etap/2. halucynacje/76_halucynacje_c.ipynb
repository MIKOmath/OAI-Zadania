{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wykrywanie Halucynacji\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/65535/54208132682_73767c3560_b.jpg\" alt=\"Embedded Photo\" width=\"500\">\n",
    "\n",
    "*Obraz wygenerowany przy użyciu modelu DALL-E.*\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "Modele językowe pomagają nam w codziennych zadaniach, takich jak poprawianie tekstów, pisanie kodu czy odpowiadanie na pytania. \n",
    "Są one również coraz częściej wykorzystywane w takich dziedzinach jak medycyna czy edukacja.\n",
    "\n",
    "Jednak skąd możemy wiedzieć, czy wygenerowane przez nie odpowiedzi są poprawne? Modele językowe nie zawsze posiadają pełną wiedzę na zadany temat, a mimo to mogą formułować odpowiedzi, które brzmią wiarygodnie, lecz w rzeczywistości wprowadzają w błąd. Takie niepoprawne odpowiedzi nazywamy halucynacjami.\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "W tym zadaniu zmierzysz się z wykrywaniem halucynacji w odpowiedziach na pytania faktograficzne generowane przez duże modele językowe (LLM).\n",
    "Przeanalizujesz zbiór danych, który pomoże w ocenie, czy odpowiedzi generowane przez model językowy są faktycznie poprawne, czy zawierają halucynacje.\n",
    "\n",
    "Każdy przykład w zbiorze danych zawiera:\n",
    "\n",
    "- **Pytanie** np. \"Jaka jest główna odpowiedzialność Departamentu Obrony USA?\"\n",
    "- **Odpowiedź modelu językowego** np. \"Główną odpowiedzialnością jest obrona kraju.\"\n",
    "- **Tokeny** związane z generacją odpowiedzi.\n",
    "- **Cztery alternatywne odpowiedzi** wygenerowane z przez ten sam model z większą temperaturą.\n",
    "- **Tokeny alternatywnych odpowiedzi** wygenerowane z przez ten sam model z większą temperaturą.\n",
    "- **Prawdopodobieństwa alternatywnych odpowiedzi** wygenerowane z przez ten sam model z większą temperaturą.\n",
    "- **Etykietę (`is_correct`)** wskazującą, czy główna odpowiedź jest poprawna według zaufanego źródła.\n",
    "\n",
    "\n",
    "Przykład:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"question_id\": 34,\n",
    "        \"question\": \"What is the name of the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines?\",\n",
    "        \"answer\": \"Scoot is the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines.\",\n",
    "        \"tokens\": [\" Sco\", \"ot\", \" is\", ..., \" Airlines\", \".\", \"\\n\"],\n",
    "        \"supporting_answers\": [\n",
    "            \"As a wholly owned subsidiary of Singapore Airlines, <answer> Scoot </answer> stands as a low-cost carrier that revolutionized air travel in the region.\",\n",
    "            \"Scoot, a subsidiary of <answer> Singapore Airlines </answer> , is the low-cost carrier that operates under the same brand.\",\n",
    "            \"<answer> Scoot </answer> is the low-cost carrier that operates as a wholly owned subsidiary of Singapore Airlines.\",\n",
    "            \"Singapore Airlines operates a low-cost subsidiary named <answer> Scoot </answer> , offering affordable and efficient air travel options to passengers.\"\n",
    "        ],\n",
    "        \"supporting_tokens\": [\n",
    "            [\" As\", \" a\", ..., \".\", \"<answer>\"],\n",
    "            [\" Sco\", \"ot\", ..., \" brand\", \".\", \"\\n\"],\n",
    "            [\"<answer>\", \" Sco\", ..., \".\", \"\\n\"],\n",
    "            [\" Singapore\", \" Airlines\", ..., \".\", \"\\n\"]\n",
    "        ],\n",
    "        \"supporting_probabilities\": [\n",
    "            [0.0029233775567263365, 0.8621460795402527, ..., 0.018515007570385933],\n",
    "            [0.42073577642440796, 0.9999748468399048, ..., 0.9166142344474792],\n",
    "            [0.3258324861526489, 0.9969879984855652, ..., 0.921079695224762],\n",
    "            [0.11142394691705704, 0.960810661315918, ..., 0.9557166695594788]\n",
    "        ],\n",
    "        \"is_correct\": true\n",
    "    },\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```\n",
    "\n",
    "### Dane\n",
    "Dane dostępne dla Ciebie w tym zadaniu to:\n",
    "\n",
    "* `train.json` - zbiór danych zawierający 2967 pytań oraz odpowiedzi.\n",
    "* `valid.json` - 990 dodatkowych pytań.\n",
    "\n",
    "\n",
    "### Kryterium Oceny\n",
    "\n",
    "ROC AUC (ang. *Receiver Operating Characteristic Area Under Curve*) to miara jakości klasyfikatora binarnego. Pokazuje zdolność modelu do odróżniania między dwiema klasami - tutaj halucynacją (false) i poprawną odpowiedzią (true). \n",
    "\n",
    "- **ROC (Receiver Operating Characteristic)**: Wykres pokazujący zależność między *True Positive Rate* (czułość) a *False Positive Rate* (1-specyficzność) przy różnych progach decyzyjnych.\n",
    "- **AUC (Area Under Curve)**: Pole pod wykresem ROC, które przyjmuje wartości od 0 do 1:\n",
    "  - **1.0**: Model perfekcyjny.\n",
    "  - **0.5**: Model losowy (brak zdolności do odróżniania klas).\n",
    "\n",
    "Im wyższa wartość AUC, tym lepiej model radzi sobie z klasyfikacją.\n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Wynik będzie skalowany liniowo w zależności od wartości ROC AUC:\n",
    "\n",
    "- **ROC AUC ≤ 0.7**: 0 punktów.\n",
    "- **ROC AUC ≥ 0.82**: 100 punktów.\n",
    "- **Wartości pomiędzy 0.7 a 0.82**: skalowane liniowo.\n",
    "\n",
    "Wzór na wynik:  \n",
    "$$\n",
    "\\text{Punkty} = \n",
    "\\begin{cases} \n",
    "0 & \\text{dla } \\text{ROC AUC} \\leq 0.7 \\\\\n",
    "100 \\times \\frac{\\text{ROC AUC} - 0.7}{0.82 - 0.7} & \\text{dla } 0.7 < \\text{ROC AUC} < 0.82 \\\\\n",
    "100 & \\text{dla } \\text{ROC AUC} \\geq 0.82\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "## Ograniczenia\n",
    "* Twoje rozwiazanie będzie testowane na Platformie Konkursowej bez dostępu do internetu oraz w środowisku bez GPU.\n",
    "* Ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie może trwać dłużej niż 5 minut bez GPU.\n",
    "* Lista dopuszczalnych bibliotek: `xgboost`, `scikit-learn`, `numpy`, `pandas`, `matplotlib`.\n",
    "\n",
    "\n",
    "## Pliki Zgłoszeniowe\n",
    "Ten notebook uzupełniony o Twoje rozwiązanie (patrz funkcja `predict_hallucinations`).\n",
    "\n",
    "## Ewaluacja\n",
    "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
    "\n",
    "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kod Startowy\n",
    "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1TGEDaxw4GKfSq0fpqSk0wRpUSc8GgZN0\n",
      "To: /home/hubert/Documents/Programs/Python/AI/II-OlimpiadaAI/1_etap/2_wykrywanie_halucynacji/data/train.json\n",
      "100%|██████████| 14.2M/14.2M [00:00<00:00, 38.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qrr7bZk6Uct8DeC-V8Bc1qD5su56ryFd\n",
      "To: /home/hubert/Documents/Programs/Python/AI/II-OlimpiadaAI/1_etap/2_wykrywanie_halucynacji/data/valid.json\n",
      "100%|██████████| 4.77M/4.77M [00:00<00:00, 24.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: valid.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "FINAL_EVALUATION_MODE = False  # W czasie sprawdzania twojego rozwiązania, zmienimy tą wartość na True\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import shutil\n",
    "\n",
    "def download_data(train=(\"1TGEDaxw4GKfSq0fpqSk0wRpUSc8GgZN0\", \"train.json\"),\n",
    "                  valid=(\"1qrr7bZk6Uct8DeC-V8Bc1qD5su56ryFd\", \"valid.json\")):\n",
    "    \"\"\"Pobiera zbiór danych z Google Drive i zapisuje go w folderze 'data'.\"\"\"\n",
    "    import gdown\n",
    "    \n",
    "    # Utwórz lub zresetuj folder 'data'\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    else:\n",
    "        shutil.rmtree('data')\n",
    "        os.makedirs('data')\n",
    "\n",
    "    GDRIVE_DATA = [train, valid]\n",
    "    \n",
    "    for file_id, file_name in GDRIVE_DATA:        \n",
    "        # Pobierz plik z Google Drive i zapisz go w folderze 'data'\n",
    "        url = f'https://drive.google.com/uc?id={file_id}'\n",
    "        output = f'data/{file_name}'\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        \n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "# Pobierz dane tylko jeśli nie jesteś w trybie FINAL_EVALUATION_MODE\n",
    "if not FINAL_EVALUATION_MODE:\n",
    "    download_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie Danych\n",
    "Za pomocą poniższego kodu dane zostaną wczytane i odpowiednio przygotowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"question_id\": 2147,\n",
      "  \"question\": \"What is the name of the American multinational toy manufacturing and entertainment company founded in 1945?\",\n",
      "  \"answer\": \"With a rich history spanning decades, the name of the American multinational toy manufacturing and entertainment company founded in 1945 is Hasbro .\",\n",
      "  \"tokens\": [\n",
      "    \" With\",\n",
      "    \" a\",\n",
      "    \" rich\",\n",
      "    \" history\",\n",
      "    \" spanning\",\n",
      "    \" decades\",\n",
      "    \",\",\n",
      "    \" the\",\n",
      "    \" name\",\n",
      "    \" of\",\n",
      "    \" the\",\n",
      "    \" American\",\n",
      "    \" multinational\",\n",
      "    \" toy\",\n",
      "    \" manufacturing\",\n",
      "    \" and\",\n",
      "    \" entertainment\",\n",
      "    \" company\",\n",
      "    \" founded\",\n",
      "    \" in\",\n",
      "    \" \",\n",
      "    \"1\",\n",
      "    \"9\",\n",
      "    \"4\",\n",
      "    \"5\",\n",
      "    \" is\",\n",
      "    \" Hasbro\",\n",
      "    \".\",\n",
      "    \"\\n\"\n",
      "  ],\n",
      "  \"supporting_answers\": [\n",
      "    \"The iconic American toy manufacturing and entertainment company, known for its beloved characters, is <answer> Hasbro </answer> .\",\n",
      "    \"Mattel, the American multinational toy manufacturing and entertainment company, was founded by <answer> Ruth Handler </answer> in 1945.\",\n",
      "    \"With a rich history and a global presence, <answer> Hasbro </answer> is the name of the American multinational toy manufacturing and entertainment company founded in 1945.\",\n",
      "    \"A household name, <answer> Hasbro </answer> is the name of this iconic American toy manufacturing and entertainment company.\"\n",
      "  ],\n",
      "  \"supporting_tokens\": [\n",
      "    [\n",
      "      \" The\",\n",
      "      \" iconic\",\n",
      "      \" American\",\n",
      "      \" toy\",\n",
      "      \" manufacturing\",\n",
      "      \" and\",\n",
      "      \" entertainment\",\n",
      "      \" company\",\n",
      "      \",\",\n",
      "      \" known\",\n",
      "      \" for\",\n",
      "      \" its\",\n",
      "      \" beloved\",\n",
      "      \" characters\",\n",
      "      \",\",\n",
      "      \" is\",\n",
      "      \"<answer>\",\n",
      "      \" Hasbro\",\n",
      "      \"</answer>\",\n",
      "      \".\",\n",
      "      \"\\n\"\n",
      "    ],\n",
      "    [\n",
      "      \" Mattel\",\n",
      "      \",\",\n",
      "      \" the\",\n",
      "      \" American\",\n",
      "      \" multinational\",\n",
      "      \" toy\",\n",
      "      \" manufacturing\",\n",
      "      \" and\",\n",
      "      \" entertainment\",\n",
      "      \" company\",\n",
      "      \",\",\n",
      "      \" was\",\n",
      "      \" founded\",\n",
      "      \" by\",\n",
      "      \"<answer>\",\n",
      "      \" Ruth\",\n",
      "      \" Handler\",\n",
      "      \"</answer>\",\n",
      "      \" in\",\n",
      "      \" \",\n",
      "      \"1\",\n",
      "      \"9\",\n",
      "      \"4\",\n",
      "      \"5\",\n",
      "      \".\",\n",
      "      \"\\n\"\n",
      "    ],\n",
      "    [\n",
      "      \" With\",\n",
      "      \" a\",\n",
      "      \" rich\",\n",
      "      \" history\",\n",
      "      \" and\",\n",
      "      \" a\",\n",
      "      \" global\",\n",
      "      \" presence\",\n",
      "      \",\",\n",
      "      \"<answer>\",\n",
      "      \" Hasbro\",\n",
      "      \"</answer>\",\n",
      "      \" is\",\n",
      "      \" the\",\n",
      "      \" name\",\n",
      "      \" of\",\n",
      "      \" the\",\n",
      "      \" American\",\n",
      "      \" multinational\",\n",
      "      \" toy\",\n",
      "      \" manufacturing\",\n",
      "      \" and\",\n",
      "      \" entertainment\",\n",
      "      \" company\",\n",
      "      \" founded\",\n",
      "      \" in\",\n",
      "      \" \",\n",
      "      \"1\",\n",
      "      \"9\",\n",
      "      \"4\",\n",
      "      \"5\",\n",
      "      \".\",\n",
      "      \"\\n\"\n",
      "    ],\n",
      "    [\n",
      "      \" A\",\n",
      "      \" household\",\n",
      "      \" name\",\n",
      "      \",\",\n",
      "      \"<answer>\",\n",
      "      \" Hasbro\",\n",
      "      \"</answer>\",\n",
      "      \" is\",\n",
      "      \" the\",\n",
      "      \" name\",\n",
      "      \" of\",\n",
      "      \" this\",\n",
      "      \" iconic\",\n",
      "      \" American\",\n",
      "      \" toy\",\n",
      "      \" manufacturing\",\n",
      "      \" and\",\n",
      "      \" entertainment\",\n",
      "      \" company\",\n",
      "      \".\",\n",
      "      \"\\n\"\n",
      "    ]\n",
      "  ],\n",
      "  \"supporting_probabilities\": [\n",
      "    [\n",
      "      0.23243841528892517,\n",
      "      0.12518402934074402,\n",
      "      0.6196073293685913,\n",
      "      0.9381160140037537,\n",
      "      0.33835962414741516,\n",
      "      0.7738495469093323,\n",
      "      0.9994743466377258,\n",
      "      0.9691826105117798,\n",
      "      0.8523021936416626,\n",
      "      0.14938969910144806,\n",
      "      0.9876048564910889,\n",
      "      0.9777396321296692,\n",
      "      0.18107247352600098,\n",
      "      0.6601294875144958,\n",
      "      0.33072152733802795,\n",
      "      0.9472849369049072,\n",
      "      0.9298351407051086,\n",
      "      0.6534764766693115,\n",
      "      0.9324541091918945,\n",
      "      0.9396570324897766,\n",
      "      0.9460866451263428\n",
      "    ],\n",
      "    [\n",
      "      0.12555915117263794,\n",
      "      0.9545625448226929,\n",
      "      0.5498789548873901,\n",
      "      0.2886303961277008,\n",
      "      0.7931939363479614,\n",
      "      0.9966543912887573,\n",
      "      0.9905881881713867,\n",
      "      0.9911351203918457,\n",
      "      0.9999561309814453,\n",
      "      0.9997197985649109,\n",
      "      0.44820770621299744,\n",
      "      0.9147195816040039,\n",
      "      0.9707311391830444,\n",
      "      0.03225848451256752,\n",
      "      0.9596169590950012,\n",
      "      0.94599449634552,\n",
      "      0.9900554418563843,\n",
      "      0.9170762300491333,\n",
      "      0.798942506313324,\n",
      "      0.8295739889144897,\n",
      "      0.9999939203262329,\n",
      "      0.999996542930603,\n",
      "      0.9999743700027466,\n",
      "      0.999901294708252,\n",
      "      0.988368570804596,\n",
      "      0.9265382885932922\n",
      "    ],\n",
      "    [\n",
      "      0.463106632232666,\n",
      "      0.76554936170578,\n",
      "      0.38345128297805786,\n",
      "      0.9516579508781433,\n",
      "      0.45744308829307556,\n",
      "      0.4446282982826233,\n",
      "      0.39993157982826233,\n",
      "      0.8672053217887878,\n",
      "      0.9992079138755798,\n",
      "      0.9249110221862793,\n",
      "      0.47122323513031006,\n",
      "      0.9395498037338257,\n",
      "      0.942444384098053,\n",
      "      0.9158676862716675,\n",
      "      0.9339720010757446,\n",
      "      0.9647195339202881,\n",
      "      0.9933847784996033,\n",
      "      0.9728797674179077,\n",
      "      0.9608033895492554,\n",
      "      0.9999004602432251,\n",
      "      0.9988434314727783,\n",
      "      0.9989442229270935,\n",
      "      0.9999637603759766,\n",
      "      0.9999231100082397,\n",
      "      0.93906170129776,\n",
      "      0.9999488592147827,\n",
      "      0.9999046325683594,\n",
      "      0.9999986886978149,\n",
      "      0.9999997615814209,\n",
      "      0.9999961853027344,\n",
      "      0.9999731779098511,\n",
      "      0.9993205070495605,\n",
      "      0.9041101336479187\n",
      "    ],\n",
      "    [\n",
      "      0.038162313401699066,\n",
      "      0.6450687646865845,\n",
      "      0.9999451637268066,\n",
      "      0.1747877448797226,\n",
      "      0.7557858824729919,\n",
      "      0.6472688913345337,\n",
      "      0.963648796081543,\n",
      "      0.7316440939903259,\n",
      "      0.7335038781166077,\n",
      "      0.5409312844276428,\n",
      "      0.9965502023696899,\n",
      "      0.003265992272645235,\n",
      "      0.3706514239311218,\n",
      "      0.3019772171974182,\n",
      "      0.9385819435119629,\n",
      "      0.35919639468193054,\n",
      "      0.5800549983978271,\n",
      "      0.9997933506965637,\n",
      "      0.9959347248077393,\n",
      "      0.8386197090148926,\n",
      "      0.96028733253479\n",
      "    ]\n",
      "  ],\n",
      "  \"is_correct\": false\n",
      "}\n",
      "\n",
      "Wszystkie przykłady treningowe: 2967\n",
      "Wszystkie przykłady walidacyjne: 990\n"
     ]
    }
   ],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "def load_data(folder='data'):\n",
    "    # Wczytaj dane z plików\n",
    "    train_path = os.path.join(folder, 'train.json')\n",
    "    valid_path = os.path.join(folder, 'valid.json')\n",
    "    \n",
    "    with open(train_path, 'r') as f:\n",
    "        train = json.load(f)\n",
    "    with open(valid_path, 'r') as f:\n",
    "        valid = json.load(f)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "train, valid = load_data(\"data\")\n",
    "\n",
    "print(json.dumps(train[0], indent=2))\n",
    "\n",
    "print(f\"\\nWszystkie przykłady treningowe: {len(train)}\")\n",
    "print(f\"Wszystkie przykłady walidacyjne: {len(valid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod z Kryterium Oceniającym\n",
    "\n",
    "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "\n",
    "def compute_score(roc_auc: float) -> float:\n",
    "    \"\"\"\n",
    "    Oblicza wynik punktowy na podstawie wartości ROC AUC.\n",
    "\n",
    "    :param roc_auc: Wartość float w zakresie [0.0, 1.0]\n",
    "    :return: Wynik punktowy zgodny z określoną funkcją\n",
    "    \"\"\"\n",
    "    if roc_auc <= 0.7:\n",
    "        return 0\n",
    "    elif 0.7 < roc_auc < 0.82:\n",
    "        return int(round(100 * (roc_auc - 0.7) / (0.82 - 0.7)))\n",
    "    else:\n",
    "        return 100\n",
    "\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, verbose=False):\n",
    "    \"\"\"\n",
    "    Ewaluacja algorytmu wykrywania halucynacji na podanym zbiorze danych.\n",
    "\n",
    "    Parametry\n",
    "    ----------\n",
    "    dataset : list\n",
    "        Oznaczony zbiór danych, gdzie każdy element to słownik zawierający klucz 'is_correct'.\n",
    "    algorithm : callable\n",
    "        Funkcja, która przyjmuje pojedynczy przykład (słownik) i zwraca prawdopodobieństwo halucynacji.\n",
    "    verbose : bool\n",
    "        Jeśli True, wypisuje dodatkowe informacje dla każdego przykładu oraz podsumowanie.\n",
    "\n",
    "    Zwraca\n",
    "    -------\n",
    "    roc_auc : float\n",
    "        Wartość pola pod krzywą ROC (ROC AUC) dla predykcji.\n",
    "    \"\"\"\n",
    "    predicted_ys = [] # Lista przechowująca przewidywane prawdopodobieństwa halucynacji\n",
    "\n",
    "    for i, entry in enumerate(dataset):\n",
    "        # Tworzenie kopii próbki i usunięcie etykiety, aby uzyskać dane wejściowe bez oznaczeń\n",
    "        sample_unlabeled = dict(entry)\n",
    "        sample_unlabeled.pop('is_correct', None)\n",
    "\n",
    "        try:\n",
    "            # Przewidywanie prawdopodobieństwa dla pojedynczej próbki\n",
    "            pred_prob = algorithm(sample_unlabeled)\n",
    "            predicted_ys.append(pred_prob)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Jeśli wystąpi błąd, domyślnie ustawiamy prawdopodobieństwo na 0.5\n",
    "            predicted_ys.append(0.5)\n",
    "            if verbose:\n",
    "                print(f\"Sample {i} => Error: {e}\")\n",
    "\n",
    "    predicted_ys = np.array(predicted_ys, dtype=np.float32)\n",
    "    ys = []\n",
    "    for entry in dataset:\n",
    "        ys.append(1 if entry.get('is_correct') else 0)\n",
    "    ys = np.array(ys, dtype=np.int32)\n",
    "    \n",
    "    # Obliczenie metryki ROC AUC\n",
    "    roc_auc = roc_auc_score(ys, predicted_ys)\n",
    "\n",
    "    # Obliczenie końcowego wyniku na podstawie ROC AUC\n",
    "    points = compute_score(roc_auc)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nLiczba próbek: {len(dataset)}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        print(f\"Wynik punktowy: {points}\")\n",
    "\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twoje Rozwiązanie\n",
    "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consensus_score(original_answer, extracted_answers, supporting_probabilities):\n",
    "    \"\"\"\n",
    "    Computes an improved consensus score using weighted voting, token overlap, \n",
    "    and soft similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - original_answer: The ground truth answer.\n",
    "    - extracted_answers: List of extracted answers from supporting evidence.\n",
    "    - supporting_probabilities: List of probabilities associated with each supporting answer.\n",
    "    \n",
    "    Returns:\n",
    "    - consensus_score: A float value representing the agreement level.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If no extracted answers exist, return 0\n",
    "    if not extracted_answers:\n",
    "        return 0.0\n",
    "\n",
    "    # Count occurrences of each extracted answer\n",
    "    answer_counter = Counter(extracted_answers)\n",
    "\n",
    "    # Most common answer and its count\n",
    "    most_common_answer, most_common_count = answer_counter.most_common(1)[0]\n",
    "\n",
    "    # Compute Jaccard similarity between original and most common answer\n",
    "    def jaccard_similarity(a, b):\n",
    "        set_a, set_b = set(a.lower().split()), set(b.lower().split())\n",
    "        return len(set_a & set_b) / len(set_a | set_b)\n",
    "\n",
    "    jaccard_sim = jaccard_similarity(original_answer, most_common_answer)\n",
    "\n",
    "    # Weighted agreement score using supporting probabilities\n",
    "    answer_scores = {ans: 0 for ans in answer_counter}\n",
    "    \n",
    "    for ans, prob in zip(extracted_answers, supporting_probabilities):\n",
    "        answer_scores[ans] += prob  # Sum probabilities for the same answer\n",
    "\n",
    "    # Normalize scores (convert to probability distribution)\n",
    "    total_score = sum(answer_scores.values())\n",
    "    weighted_agreement = answer_scores[most_common_answer] / total_score if total_score > 0 else 0\n",
    "\n",
    "    # Final consensus score: weighted agreement + soft similarity\n",
    "    consensus_score = 0.7 * weighted_agreement + 0.3 * jaccard_sim\n",
    "\n",
    "    return consensus_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(probabilities):\n",
    "    \"\"\"Compute entropy of a probability distribution.\"\"\"\n",
    "    probabilities = np.clip(probabilities, 1e-9, 1)  # Avoid log(0)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def extract_answer_text(supporting_answer):\n",
    "    \"\"\"Extracts the answer inside <answer> ... </answer> tags.\"\"\"\n",
    "    start = supporting_answer.find(\"<answer>\")\n",
    "    end = supporting_answer.find(\"</answer>\")\n",
    "    if start != -1 and end != -1:\n",
    "        return supporting_answer[start + 8:end].strip()\n",
    "    return \"\"\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    \"\"\"Computes Jaccard similarity between two texts.\"\"\"\n",
    "    set1, set2 = set(text1.split()), set(text2.split())\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Compute Levenshtein distance manually (since we can't use extra packages).\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = np.arange(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "def extract_features(samples, is_validation=False):\n",
    "    features = []\n",
    "    labels = [] if not is_validation else None  \n",
    "\n",
    "    for sample in samples:\n",
    "        answer_length = len(sample[\"tokens\"])  \n",
    "        num_supporting = len(sample[\"supporting_answers\"])  \n",
    "        unique_tokens = len(set(sample[\"tokens\"]))  \n",
    "\n",
    "        # Aggregate supporting probabilities\n",
    "        supporting_probs = np.concatenate(sample[\"supporting_probabilities\"])\n",
    "        \n",
    "        avg_supporting_prob = np.mean(supporting_probs)\n",
    "        max_supporting_prob = np.max(supporting_probs)\n",
    "        min_supporting_prob = np.min(supporting_probs)\n",
    "        var_supporting_prob = np.var(supporting_probs)\n",
    "        entropy_supporting_prob = compute_entropy(supporting_probs)\n",
    "\n",
    "        # Token-level probabilities\n",
    "        token_wise_variance = np.mean([np.var(probs) for probs in sample[\"supporting_probabilities\"]])\n",
    "        token_wise_max_prob = np.mean([np.max(probs) for probs in sample[\"supporting_probabilities\"]])\n",
    "\n",
    "        # Position-based features\n",
    "        max_prob_position = np.argmax(supporting_probs) / len(supporting_probs)\n",
    "        min_prob_position = np.argmin(supporting_probs) / len(supporting_probs)\n",
    "\n",
    "        # Extracted answer comparison\n",
    "        original_answer = sample[\"answer\"]\n",
    "        extracted_answers = [extract_answer_text(sup) for sup in sample[\"supporting_answers\"]]\n",
    "        extracted_answers = [ans for ans in extracted_answers if ans]  # Remove empty extracted answers\n",
    "\n",
    "        jaccard_sim_values = [jaccard_similarity(original_answer, ans) for ans in extracted_answers]\n",
    "        levenshtein_dist_values = [levenshtein_distance(original_answer, ans) for ans in extracted_answers]\n",
    "\n",
    "        avg_jaccard_sim = np.mean(jaccard_sim_values) if jaccard_sim_values else 0\n",
    "        avg_levenshtein_dist = np.mean(levenshtein_dist_values) if levenshtein_dist_values else 0\n",
    "\n",
    "        # Compare extracted answers with each other (consistency check)\n",
    "        pairwise_jaccard = []\n",
    "        pairwise_levenshtein = []\n",
    "\n",
    "        for ans1, ans2 in combinations(extracted_answers, 2):\n",
    "            pairwise_jaccard.append(jaccard_similarity(ans1, ans2))\n",
    "            pairwise_levenshtein.append(levenshtein_distance(ans1, ans2))\n",
    "\n",
    "        avg_pairwise_jaccard = np.mean(pairwise_jaccard) if pairwise_jaccard else 0\n",
    "        avg_pairwise_levenshtein = np.mean(pairwise_levenshtein) if pairwise_levenshtein else 0\n",
    "\n",
    "        # Majority consensus: Check how often the most common answer appears\n",
    "        if extracted_answers:\n",
    "            most_common_answer = max(set(extracted_answers), key=extracted_answers.count)\n",
    "            consensus_score = extracted_answers.count(most_common_answer) / len(extracted_answers)\n",
    "        else:\n",
    "            most_common_answer = \"\"\n",
    "            consensus_score = 0\n",
    "\n",
    "        another_consensus_score = compute_consensus_score(original_answer, extracted_answers, supporting_probs)\n",
    "\n",
    "        # New feature: Compare the most common answer to the original answer\n",
    "        most_common_jaccard = jaccard_similarity(original_answer, most_common_answer)\n",
    "        most_common_levenshtein = levenshtein_distance(original_answer, most_common_answer)\n",
    "\n",
    "        # Feature vector\n",
    "        feature_vector = [\n",
    "            answer_length,\n",
    "            avg_supporting_prob, \n",
    "            entropy_supporting_prob,\n",
    "            token_wise_variance,\n",
    "            avg_jaccard_sim, \n",
    "            avg_pairwise_jaccard, consensus_score, another_consensus_score,\n",
    "            most_common_jaccard, most_common_levenshtein  # New features\n",
    "        ]\n",
    "        features.append(feature_vector)\n",
    "\n",
    "        # Store label only if available\n",
    "        if not is_validation:\n",
    "            labels.append(sample[\"is_correct\"])\n",
    "\n",
    "    if is_validation:\n",
    "        return np.array(features)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='auc', feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = extract_features(train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# selector = RFECV(RandomForestClassifier(n_estimators=100, random_state=42), step=1, cv=5)\n",
    "# X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 300, 500, 700, 900, 100],  # Number of trees\n",
    "#     'learning_rate': [0.001, 0.002, 0.003, 0.005, 0.007, 0.008, 0.009, 0.01, 0.02, 0.05, 0.1, 0.2],  # Step size\n",
    "#     'max_depth': [2, 3, 4, 5, 6, 9],  # Tree depth\n",
    "#     'min_child_weight': [2, 3, 4, 5],  # Minimum sum of instance weight needed in a child\n",
    "#     'subsample': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of samples used per tree\n",
    "#     'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]  # Fraction of features used per tree\n",
    "# }\n",
    "\n",
    "xgb = XGBClassifier(subsample=0.5, n_estimators=500, min_child_weight=3, max_depth=2, learning_rate=0.01, colsample_bytree=0.9, eval_metric='auc', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# random_search = RandomizedSearchCV(xgb, param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=2, n_iter=200)\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# best_model = random_search.best_estimator_\n",
    "# print(f\"Best ROC AUC: {random_search.best_score_}\")\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# feature_importances = clf.feature_importances_\n",
    "# plt.barh(range(len(feature_importances)), feature_importances)\n",
    "# plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "# importances = xgb.feature_importances_\n",
    "# plt.bar(range(len(importances)), importances)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Użyj danych treningowych, aby stworzyć tutaj model lub algorytm.\n",
    "\n",
    "# print(random_search.best_params_)\n",
    "\n",
    "def predict_hallucinations(sample):\n",
    "    # TODO: Uruchom swój model lub algorytm na tym zestawie danych.\n",
    "    # TODO: Zwróć listę prawdopodobieństw dla każdego przykładu w zestawie danych.\n",
    "\n",
    "    X_val = extract_features([sample], is_validation=True)\n",
    "    X_val = scaler.transform(X_val)  # Use the same scaler\n",
    "\n",
    "    prediction_probs = xgb.predict_proba(X_val)[:, 1]  # Probability of correctness\n",
    "    \n",
    "    return prediction_probs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ewaluacja\n",
    "\n",
    "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liczba próbek: 990\n",
      "ROC AUC: 0.7901\n",
      "Wynik punktowy: 75\n"
     ]
    }
   ],
   "source": [
    "if not FINAL_EVALUATION_MODE:\n",
    "    roc_auc = evaluate_algorithm(valid, predict_hallucinations, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podczas sprawdzania model zostanie zapisany jako `your_model.pkl` i oceniony na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
    "if FINAL_EVALUATION_MODE:      \n",
    "    import cloudpickle\n",
    "      \n",
    "    OUTPUT_PATH = \"file_output\"\n",
    "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
    "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
    "        cloudpickle.dump(predict_hallucinations, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OAI2025Task2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
