{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7F3RXedd92V"
      },
      "source": [
        "# Ukryte Podciągi\n",
        "![](https://live.staticflickr.com/65535/54327633282_6bc45ba42a_o.png)\n",
        "\n",
        "*Obraz wygenerowany przy użyciu modelu DALL-E.*\n",
        "\n",
        "## Wstęp\n",
        "Od starożytnych wróżbitów interpretujących układ gwiazd po współczesnych kryptografów tropiących ślady ukrytych wiadomości, ludzkość od zawsze poszukiwała sensu w pozornie chaotycznych danych. Czasem kluczowe informacje ukrywają się w drobnych sekwencjach symboli, a ich wartość ujawnia się dopiero po precyzyjnej analizie.\n",
        "\n",
        "W tym zadaniu wcielisz się w rolę detektywa, poszukującego strukturalnych zależności w zbiorze binarnych ciągów. Będziesz dysponował zbiorem danych zawierającym przykładowe ciągi oraz ich poprawnie obliczone wartości. Twoim celem będzie opracowanie metody analizy ukrytych wzorców pozwalającej na możliwie najprecyzyjniejsze wyznaczanie wartości ciągów niewystępujących w zbiorze.\n",
        "\n",
        "Mówimy, że ciąg $T$ jest podciągiem $S$ i oznaczamy $T \\subseteq S$ jeżeli\n",
        "$$\n",
        "T = S_{i_1}S_{i_2} \\dots S_{i_k}\n",
        "$$\n",
        "Gdzie\n",
        "$$\n",
        "1 \\leq i_1 < i_2 < \\dots < i_k \\leq n\n",
        "$$\n",
        "Dla $k$ i $n$ będących długościami ciągów $T$ i $S$ odpowiednio, oraz indeksów ($i_1 < i_2 < \\dots < i_k$) będących ściśle rosnącym ciągiem liczb naturalnych (niekoniecznie kolejnych).\n",
        "\n",
        "Rozwiązaniem dla danego ciągu binarnego $S \\in \\{0,1\\}^{n}$ oraz zdefiniowanego zbioru zawierającego kolejno wzorzec i jego wagę $W = \\{(T, v):T \\in \\{0,1\\}^{k}, k \\le n, v \\in Z\\}$ jest liczba\n",
        "$$\n",
        "\\phi(S) = \\sum_{(T_{i}, v_{i}) \\in W} v_{i} \\cdot \\text{I} (T_{i})\n",
        "$$\n",
        "gdzie $\\text{I}(T_{i}) = \\begin{cases}\n",
        "1, & T_{i} \\subseteq S \\\\\n",
        "0, & T_{i} \\subsetneq S\n",
        "\\end{cases}$\n",
        "\n",
        "Innymi słowy, $\\phi(S)$ jest sumą wartości wszystkich ciągów ze zbioru $W$, które są podciągami $S$.\n",
        "\n",
        "**Przykład:**\n",
        "Dla zbioru $W = \\{(1111, 1), (1010, 2)\\}$, mamy:\n",
        "- $\\phi$(0**1111**000) = 1\n",
        "- $\\phi$(1**10**00**1**0**0**) = 2\n",
        "- $\\phi$(0**110110**0) = 3,  ponieważ\n",
        "\n",
        "  - 1111 $\\subseteq$ 0**11**0**11**00\n",
        "\n",
        "  - 1010 $\\subseteq$ 01**101**1**0**0\n",
        "- $\\phi$(01100000) = 0, ponieważ 1111, 1010 $\\subsetneq$ 01100000.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV6IfA7id92W"
      },
      "source": [
        "## Zadanie\n",
        "Stwórz model (obiekt typu `nn.Module`) który będzie znajdował wartość $\\phi$ dla ciągów ze zbioru danych. Dane treningowe składają się z ciągów $S$ oraz odpowiadających im wartości $\\phi(S)$. Zauważ więc, że wzorzec $W$ jest ukryty, a Twoim zadaniem jest przybliżyć $\\phi$ bez wiedzy o nim.\n",
        "\n",
        "Twój model musi przyjmować na wejściu dane w postaci $(\\text{batch}, n)$. Natomiast na wyjściu musi zwracać wartości w postaci $(\\text{batch}, 1)$ lub $(\\text{batch},)$, gdzie $\\text{batch}$ to liczba próbek.\n",
        "\n",
        "### Dane\n",
        "Dane dostępne dla Ciebie w tym zadaniu to:\n",
        "* `train_dataset.csv`- plik z danymi na których będziesz trenować swój model\n",
        "* `val_dataset.csv`- plik z danymi na których przetestujesz swój model\n",
        "\n",
        "### Kryterium Oceny\n",
        "Zadanie zostanie ocenione na podstawie metryki [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) (Mean Squared Error), która jest jedną z najczęściej stosowanych metryk do oceny jakości regresji.  \n",
        "\n",
        "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "Gdzie $y_i$ to wartość rzeczywista, a $\\hat{y}_i$ to wartość przewidziana przez model. Wartość $i$ to numer próbki, a $n$ to liczba wszystkich próbek.\n",
        "\n",
        "Ta metryka jest już przez nas zaimplementowana w tym notebooku.\n",
        "\n",
        "**Ostatecznie Twoje rozwiązanie oceniane będzie na tajnym zbiorze testowym na podstawie metryki MSE.** Zbiór testowy nie różni się znacząco od zbioru walidacyjnego.\n",
        "\n",
        "- Gdy wartość MSE dla Twojego modelu będzie wynosiła 64 (lub więcej), otrzymasz 0 punktów za zadanie\n",
        "- Gdy wartość MSE dla Twojego modelu będzie wynosiła 64 (lub mniej), otrzymasz X punktów za zadanie, gdzie X jest zdefiniowane w następujący sposób:\n",
        "$$\n",
        "\\text{X} = \\frac{64 - MSE}{64} \\times 100\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvMFDG-od92X"
      },
      "source": [
        "## Ograniczenia\n",
        "- Twoje rozwiązanie powinno zawierać model ML/DL z wyuczalnymi parametrami. Rozwiązania czysto algorytmiczne nie będą akceptowane.\n",
        "- Twoje rozwiazanie będzie testowane na Platformie Konkursowej bez dostępu do internetu oraz w środowisku z GPU.\n",
        "- Ewaluacja Twojego finalnego rozwiązania na Platformie Konkursowej nie może trwać dłużej niż 4 minut z GPU.\n",
        "- Twój model może być trenowany maksymalnie przez 4000 iteracji, co odpowiada pojedynczemu przeiterowaniu przez zmienną ```dl``` (patrz na przykładowe rozwiązanie).\n",
        "- Twój model nie może mieć więcej niż 50000 parametrów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQjqemxd92Z"
      },
      "source": [
        "## Uwagi i Wskazówki\n",
        "- Każdy z ciągów ma taką samą, ustaloną długość.\n",
        "- Każdy z szukanych podciągów ma długość krótszą niż długość źródłowych ciągów.\n",
        "- Rozpatrujemy trzy podciągi. Każdy z nich ma przypisaną wartość, która jest liczbą całkowitą.\n",
        "- W każdym ciągu znajduje się dowolna liczba podciągów (w tym brak jakiegokolwiek z nich).\n",
        "- Ciągi i podciągi pochodzą z alfabetu binarnego oraz są reprezentowane w postaci list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzfkmFhid92Z"
      },
      "source": [
        "## Pliki Zgłoszeniowe\n",
        "Ten notebook uzupełniony o Twoje rozwiązanie (patrz klasa `YourModel` oraz trening modelu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz6YjcJgPYZA"
      },
      "source": [
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 a 100 punktów. Liczba punktów, którą zdobędziesz, będzie wyliczona na (tajnym) zbiorze testowym na Platformie Konkursowej na podstawie wyżej wspomnianego wzoru, zaokrąglona do liczby całkowitej. Jeśli Twoje rozwiązanie nie będzie spełniało powyższych kryteriów lub nie będzie wykonywać się prawidłowo, otrzymasz za zadanie 0 punktów."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tc3PBZxd92a"
      },
      "source": [
        "# Kod Startowy\n",
        "\n",
        "W tej sekcji inicjalizujemy środowisko poprzez zaimportowanie potrzebnych bibliotek i funkcji. Przygotowany kod ułatwi Tobie efektywne operowanie na danych i budowanie właściwego rozwiązania."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uabMLs-Bd92b"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "\n",
        "FINAL_EVALUATION_MODE = False # Podczas sprawdzania ustawimy tą flagę na True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bbbDUJFed92d"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "import pandas\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IrLIiHExn3Gj"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "def seed_everything(seed: int) -> None:\n",
        "    \"\"\"\n",
        "    Ustawia ziarno (seed) dla odtwarzalności wyników w Pythonie, NumPy oraz PyTorch.\n",
        "\n",
        "    Funkcja ustawia ziarno dla generatorów liczb losowych Pythonie, NumPy oraz PyTorch,\n",
        "    a także konfiguruje PyTorch do pracy w trybie deterministycznym.\n",
        "\n",
        "    Parametry:\n",
        "        seed (int): Wartość ziarna do ustawienia.\n",
        "    \"\"\"\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BQ3OGpcKd92d"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "seed_everything(12345)\n",
        "\n",
        "device = 'cuda'\n",
        "assert torch.cuda.is_available(), \"CUDA niedostępna!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7XIsA3Fd92e"
      },
      "source": [
        "## Ładowanie Danych\n",
        "Za pomocą poniższego kodu wczytujemy dane zawierające ciągi wraz z ich wartościami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mKFjUr8663z1"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "class CSVDataloader(torch.utils.data.DataLoader):\n",
        "    \"\"\"\n",
        "    Klasa CSVDataloader służy do ładowania danych z plików CSV i zwracania ich w batchach.\n",
        "\n",
        "    Przyjmuje:\n",
        "        csv_file (str): Ścieżka do pliku CSV.\n",
        "        batch_size (int): Rozmiar batcha.\n",
        "        shuffle (bool): Czy tasować dane.\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_file, batch_size=128, shuffle=True):\n",
        "\n",
        "        class CSVDataset(torch.utils.data.Dataset):\n",
        "            \"\"\"\n",
        "            Klasa CSVDataset służy do przechowywania danych z plików CSV jako pojedyncze próbki.\n",
        "            \"\"\"\n",
        "            def __init__(self, csv_file: str):\n",
        "                data = pandas.read_csv(csv_file).values\n",
        "                self.x = torch.tensor(data[:, :-1], dtype=torch.float32)  # Features\n",
        "                self.y = torch.tensor(data[:, -1], dtype=torch.float32)  # Labels\n",
        "\n",
        "            def __len__(self) -> int:\n",
        "                return len(self.x)\n",
        "\n",
        "            def __getitem__(self, idx: int) -> tuple:\n",
        "                return self.x[idx].long(), self.y[idx]\n",
        "\n",
        "        dataset = CSVDataset(csv_file)\n",
        "        self.seq_len = dataset.x.shape[1]\n",
        "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "arN5KYKe7Chf"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# Inicjalizacja treningowego zbioru danych\n",
        "train_dataset_path = \"train_dataset.csv\"\n",
        "val_dataset_path = \"val_dataset.csv\"\n",
        "\n",
        "if not os.path.exists(train_dataset_path):\n",
        "    url = \"https://drive.google.com/uc?id=1INeYNpPA_YwojuQbMizlsFsERJ-PJX-E\"\n",
        "    gdown.download(url, train_dataset_path, quiet=True)\n",
        "\n",
        "if not os.path.exists(val_dataset_path):\n",
        "    url = \"https://drive.google.com/uc?id=1oQcOMyDWVX0x76LOyp4TcFip1koRuodN\"\n",
        "    gdown.download(url, val_dataset_path, quiet=True)\n",
        "\n",
        "dl = CSVDataloader(\"train_dataset.csv\")\n",
        "val_dl = CSVDataloader(\"val_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA-aEkMpd92i"
      },
      "source": [
        "## Kod z Kryterium Oceniającym\n",
        "\n",
        "Kod, zbliżony do poniższego, będzie używany do oceny rozwiązania na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "h8EmbPHKd92i"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "def mse_criterium(\n",
        "        estimations: torch.Tensor,\n",
        "        answers: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Oblicza wartość funkcji błędu średniokwadratowego (MSE) pomiędzy predykcjami a prawdziwymi wartościami.\n",
        "\n",
        "    Parametry:\n",
        "        estimations (torch.Tensor): Predykcje modelu.\n",
        "        answers (torch.Tensor): Prawdziwe wartości.\n",
        "\n",
        "    Zwraca:\n",
        "        torch.Tensor: Wartość funkcji błędu średniokwadratowego.\n",
        "    \"\"\"\n",
        "    return torch.mean((estimations.view(-1) - answers.view(-1)) ** 2)\n",
        "\n",
        "\n",
        "def validate_model(\n",
        "        model: torch.nn.Module,\n",
        "        val_dl: torch.utils.data.DataLoader,\n",
        "    ) -> float:\n",
        "    \"\"\"\n",
        "    Waliduje model na zbiorze walidacyjnym. Zwraca uśrednioną wartość\n",
        "    funkcji błędu średniokwadratowego dla wszystkich próbek.\n",
        "\n",
        "    Parametry:\n",
        "        model (torch.nn.Module): Model do oceny.\n",
        "        val_dl (torch.utils.data.DataLoader): DataLoader z danymi walidacyjnymi.\n",
        "\n",
        "    Zwraca:\n",
        "        float: Uśredniona wartość funkcji błędu średniokwadr\n",
        "    \"\"\"\n",
        "    model = model.eval().to(device)\n",
        "    values = []\n",
        "    for x, y in val_dl:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        y_pred = model(x)\n",
        "\n",
        "        mse = mse_criterium(y_pred, y).cpu().item()\n",
        "        values.append(mse)\n",
        "\n",
        "    final_value = torch.tensor(values).mean().item()\n",
        "\n",
        "    return final_value\n",
        "\n",
        "def estimate_points(mse: float) -> int:\n",
        "    \"\"\"\n",
        "    Funkcja wyznaczająca ilość punktów za zadanie na podstawie wartości funkcji błędu średniokwadratowego.\n",
        "\n",
        "    Parametry:\n",
        "        mse (float): Wartość funkcji błędu średniokwadratowego.\n",
        "\n",
        "    Zwraca:\n",
        "        int: Ilość punktów za zadanie (0 - 100).\n",
        "    \"\"\"\n",
        "    points = max((100 * (64 - mse)) / 64, 0)\n",
        "    return int(round(points))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVL00cmkd92j"
      },
      "source": [
        "## Przykładowe Rozwiązanie\n",
        "Poniżej przedstawiamy uproszczone rozwiązanie, które służy jako przykład demonstrujący podstawową funkcjonalność notatnika. Może ono posłużyć jako punkt wyjścia do opracowania Twojego rozwiązania.\n",
        "\n",
        "Jako prosty przykład może posłuży rozwiązanie bazujące na wielowarstwowej sieci neuronowej (ang. Multi-layered perceptron, MLP).\n",
        "W tym wypadku, ciągi zer i jedynek traktujemy jako wejście do naszej sieci, natomiast jej wyjściem modelujemy wartość danego ciągu. Minimalizując błąd średniokwadratowy (ang. mean squared error, MSE) uczymy sieć prawidłowo oszacowywać wartość podciągu na bazie jego elementów.\n",
        "\n",
        "Poniższa ilustracja ukazuje w jaki sposób uczymy nasz model prawidłowo oceniać wartości ciągów.\n",
        "\n",
        "![](https://live.staticflickr.com/65535/54328760659_2e9355bb07_c.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DjJPyFPNfyxG"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Klasa reprezentująca model sieci MLP z czterema ukrytymi warstwami.\n",
        "\n",
        "    Parametry:\n",
        "        input_length (int): Długość wejścia sieci (długość sekwencji).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_length: int):\n",
        "        super(MLP, self).__init__()\n",
        "        neurons_num = [256, 128, 64, 32]\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(input_length, neurons_num[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[0], neurons_num[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[1], neurons_num[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[2], neurons_num[3]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(neurons_num[3], 1),\n",
        "        )\n",
        "\n",
        "        print(\"Liczba parametrów:\", sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Funkcja przyjmująca sekwencje danych i zwracająca predykcje ich wartości za pomocą sieci MLP.\n",
        "\n",
        "        Parametry:\n",
        "            x (torch.Tensor): Sekwencja danych.\n",
        "\n",
        "        Zwraca:\n",
        "            torch.Tensor: Predykcje wartości sekwencji.\n",
        "        \"\"\"\n",
        "        x = x.float()\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIf3UVbRn3Gk"
      },
      "source": [
        "### Trening Przykładowego Modelu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s_RzUTvRPYZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c98f23-414d-4936-d7b9-85363824d105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Liczba parametrów: 49665\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "\tmodel = MLP(dl.seq_len).to(device)\n",
        "\n",
        "\toptimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\tcriterion = nn.MSELoss()\n",
        "\n",
        "\tmodel.train()\n",
        "\tfor batch in iter(dl): # pojedyncze przeiterowanie dl - 4000 batchy\n",
        "\t\tinputs, targets = batch\n",
        "\t\tinputs, targets = inputs.to(device).long(), targets.to(device).float().unsqueeze(1)\n",
        "\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\toutputs = model(inputs)\n",
        "\n",
        "\t\tloss = criterion(outputs, targets)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTWMkBUnn3Gk"
      },
      "source": [
        "### Ewaluacja Przykładowego Rozwiązania"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddiBIuXOn3Gk",
        "outputId": "39f6c173-077a-4e82-97b0-6ef1e40fb67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Błąd średniokwadratowy: 109.82\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "# walidacja przykładowego rozwiązania\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    score = validate_model(model, val_dl)\n",
        "    print(f\"Błąd średniokwadratowy: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lI1YSi3d92k"
      },
      "source": [
        "# Twoje Rozwiązanie\n",
        "W tej sekcji należy umieścić Twoje rozwiązanie. Wprowadzaj zmiany wyłącznie tutaj!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "c-e3OF2mPYZV"
      },
      "outputs": [],
      "source": [
        "# przykładowy model, który możesz modyfikować\n",
        "\n",
        "class YourModel(nn.Module):\n",
        "    def __init__(self, sequence_len):\n",
        "        hidden_size = 16\n",
        "        super(YourModel, self).__init__()\n",
        "        # pierwotnie to było gru ale nie chce mi się zmieniać nazwy\n",
        "        self.gru1 = nn.GRU(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "        self.gru2 = nn.GRU(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "        self.gru3 = nn.GRU(input_size=1, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_size, 1)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "        self.fc3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def train_fw(self, x):\n",
        "      _, h_n_1 = self.gru1(x)\n",
        "      _, h_n_2 = self.gru2(x)\n",
        "      _, h_n_3 = self.gru3(x)\n",
        "\n",
        "      logits1 = self.fc1(h_n_1.view(x.shape[0], 16))\n",
        "      logits2 = self.fc2(h_n_2.view(x.shape[0], 16))\n",
        "      logits3 = self.fc3(h_n_3.view(x.shape[0], 16))\n",
        "\n",
        "      return logits1, logits2, logits3\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Funkcja przyjmująca sekwencje danych i zwracająca predykcje ich wartości.\n",
        "\n",
        "        Parametry:\n",
        "            x (torch.Tensor): Sekwencja danych.\n",
        "\n",
        "        Zwraca:\n",
        "            torch.Tensor: Predykcje wartości sekwencji.\n",
        "        \"\"\"\n",
        "\n",
        "        x = x[:, :, None].float().to(device)\n",
        "\n",
        "        _, h_n_1 = self.gru1(x)\n",
        "        _, h_n_2 = self.gru2(x)\n",
        "        _, h_n_3 = self.gru3(x)\n",
        "\n",
        "        logits1 = (self.fc1(h_n_1.view(x.shape[0], self.hidden_size))[:, 0] > 0).int().to(device)\n",
        "        logits2 = (self.fc2(h_n_2.view(x.shape[0], self.hidden_size))[:, 0] > 0).int().to(device)\n",
        "        logits3 = (self.fc3(h_n_3.view(x.shape[0], self.hidden_size))[:, 0] > 0).int().to(device)\n",
        "\n",
        "        tab = []\n",
        "        for a, b, c in zip(logits1, logits2, logits3):\n",
        "          tab.append(a * (-19) + b * 11 + c * 47)\n",
        "\n",
        "        return torch.tensor(tab).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usg8rSA8PYZV"
      },
      "source": [
        "### Trening Twojego Modelu\n",
        "Tutaj zaimplementuj trening Twojego modelu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "xXhC3m-8n3Gk"
      },
      "outputs": [],
      "source": [
        "your_model = YourModel(dl.seq_len).to(device)\n",
        "\n",
        "def train_my_model(your_model):\n",
        "  criterion = torch.nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(your_model.parameters(), lr=1e-2)\n",
        "\n",
        "  best_model = None\n",
        "  best_loss = float(\"infinity\")\n",
        "\n",
        "  # na podstawie wagi możemy jednoznacznie odtworzyć, czy kolejne 3 sekwencje w W są podsekwencjami S\n",
        "  # nie możemy jednak odtworzyć tychże sekwencji\n",
        "  # dlatego będziemy potrzebować modelu (modeli), który dla każdej sekwencji przewidzi, czy jest ona podsekwencją S\n",
        "  # print(torch.unique(y))\n",
        "  # alternatywa - przewidywanie klasy wagi za pomocą mlp/rnn\n",
        "  weight_to_labels = {\n",
        "    -8: torch.tensor([1, 1, 0]).int().to(device),\n",
        "    0: torch.tensor([0, 0, 0]).int().to(device),\n",
        "    58: torch.tensor([0, 1, 1]).int().to(device),\n",
        "    28: torch.tensor([1, 0, 1]).int().to(device),\n",
        "    39: torch.tensor([1, 1, 1]).int().to(device),\n",
        "    -19: torch.tensor([1, 0, 0]).int().to(device),\n",
        "    11: torch.tensor([0, 1, 0]).int().to(device),\n",
        "    47: torch.tensor([0, 0, 1]).int().to(device),\n",
        "  }\n",
        "\n",
        "  for i, tr_batch in enumerate(dl):\n",
        "    your_model.train()\n",
        "\n",
        "    X, y = tr_batch\n",
        "    y = torch.stack([weight_to_labels[int(y_i.item())] for y_i in y]).to(device)\n",
        "    X = X[:, :, None].float().to(device)\n",
        "\n",
        "    logits1, logits2, logits3 = your_model.train_fw(X)\n",
        "\n",
        "    loss = criterion(logits1, y[:, 0, None].float()) + criterion(logits2, y[:, 1, None].float()) + criterion(logits3, y[:, 2, None].float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (i+1)%50 != 0:\n",
        "      continue\n",
        "\n",
        "    your_model.eval()\n",
        "    eval_loss = []\n",
        "    j = 0\n",
        "    with torch.no_grad():\n",
        "      for batch in val_dl:\n",
        "        j += 1\n",
        "        X, y = batch\n",
        "        y = torch.stack([weight_to_labels[int(y_i.item())] for y_i in y]).to(device)\n",
        "        X = X[:, :, None].float().to(device)\n",
        "\n",
        "        # ponieważ ostateczne predykcja musi odbywac się w forward, będziemy ręcznie przechodzić przez kolejne wartstwy modelu\n",
        "        # forward natomiast będzie nieróżniczkowalne\n",
        "        # wsm mozna uzyc tylko jednego rnna i 3 roznych fc\n",
        "        # na upartego 1 fc by wystarczyl i jakies BCELoss ale nie chce sie az tak bawic\n",
        "\n",
        "        logits1, logits2, logits3 = your_model.train_fw(X)\n",
        "\n",
        "        loss = criterion(logits1, y[:, 0, None].float()) + criterion(logits2, y[:, 1, None].float()) + criterion(logits3, y[:, 2, None].float())\n",
        "        eval_loss.append(loss)\n",
        "\n",
        "        if j > 100:\n",
        "          break\n",
        "\n",
        "    l = torch.stack(eval_loss).mean()\n",
        "    if l < best_loss:\n",
        "      best_loss = l\n",
        "      best_model = YourModel(dl.seq_len).to(device)\n",
        "      best_model.load_state_dict(your_model.state_dict())\n",
        "\n",
        "  return best_model\n",
        "\n",
        "your_model = train_my_model(your_model)\n",
        "your_model = your_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8QbP1jZd92l"
      },
      "source": [
        "# Ewaluacja\n",
        "\n",
        "Uruchomienie poniższej komórki pozwoli sprawdzić, ile punktów zdobyłoby Twoje rozwiązanie na danych walidacyjnych. Przed wysłaniem upewnij się, że cały notebook wykonuje się od początku do końca bez błędów i bez konieczności ingerencji użytkownika po wybraniu opcji \"Run All\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez0ToRdbPYZW"
      },
      "outputs": [],
      "source": [
        "# ######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    assert sum(p.numel() for p in your_model.parameters()) < 50000, \"Model posiada za dużo parametrów\"\n",
        "\n",
        "    mse = validate_model(your_model, val_dl)\n",
        "    score = estimate_points(mse)\n",
        "\n",
        "    print(f\"Błąd średniokwadratowy: {mse:.2f}\")\n",
        "    print(f\"Estymowane punkty za zadanie: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_BmsdkCn3Gk"
      },
      "source": [
        "Podczas sprawdzania model zostanie zapisany jako `your_model.pkl` i oceniony na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwJmbTiBn3Gk"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "if FINAL_EVALUATION_MODE:\n",
        "    import cloudpickle\n",
        "\n",
        "    OUTPUT_PATH = \"file_output\"\n",
        "    FUNCTION_FILENAME = \"your_model.pkl\"\n",
        "    FUNCTION_OUTPUT_PATH = os.path.join(OUTPUT_PATH, FUNCTION_FILENAME)\n",
        "\n",
        "    if not os.path.exists(OUTPUT_PATH):\n",
        "        os.makedirs(OUTPUT_PATH)\n",
        "\n",
        "    your_model = your_model.eval()\n",
        "\n",
        "    with open(FUNCTION_OUTPUT_PATH, \"wb\") as f:\n",
        "        cloudpickle.dump(your_model, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}